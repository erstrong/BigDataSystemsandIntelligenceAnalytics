{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "Emily Strong\n",
    "\n",
    "For this assignment I am combining my data set, [FaceScrube](http://vintage.winklerbros.net/facescrub.html), with the [CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) to create a human face detection CNN. It is a binary classifier of face/no face. I chose the CIFAR-10 because 6 of the 10 categories are animals which will help ensure that the model specifically detects human faces instead of over generalizing or detecting a particular feature (eg eyes) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "I used convert.py to resize the aligned images generated by the OpenFace pipeline from my project. I then randomly selected 50,000 of them to use in the training set. I added to this 50,000 images from the [CIFAR-10](https://www.kaggle.com/c/cifar-10). Keras comes with CIFAR-10 as one of the built-in data sets however I chose to directly download them instead to ensure they would be in the same format as the face images. Each of these images needs to be converted into an RGB numpy array and labeled as face (1) or no face (0).\n",
    "\n",
    "### 1) Create list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amaury-nolasco1600.png'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "for filename in os.listdir('train'):\n",
    "    files.append(filename)\n",
    "\n",
    "random.shuffle(files)\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Convert images to numpy arrays and create list of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for filename in files:\n",
    "    name = 'train/'+filename\n",
    "    img = Image.open( name )\n",
    "    img.load()\n",
    "    images.append(np.asarray(img)) \n",
    "    if '-' in filename:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 58,  54,  45],\n",
       "        [ 71,  58,  44],\n",
       "        [ 83,  63,  47],\n",
       "        ..., \n",
       "        [102,  83,  73],\n",
       "        [ 98,  78,  69],\n",
       "        [ 82,  70,  61]],\n",
       "\n",
       "       [[ 55,  50,  43],\n",
       "        [ 72,  62,  49],\n",
       "        [ 82,  65,  50],\n",
       "        ..., \n",
       "        [ 97,  84,  67],\n",
       "        [100,  87,  71],\n",
       "        [ 79,  70,  56]],\n",
       "\n",
       "       [[ 51,  48,  42],\n",
       "        [ 73,  68,  58],\n",
       "        [ 75,  63,  48],\n",
       "        ..., \n",
       "        [ 95,  85,  61],\n",
       "        [ 96,  88,  67],\n",
       "        [ 79,  69,  50]],\n",
       "\n",
       "       ..., \n",
       "       [[ 21,  19,  14],\n",
       "        [ 33,  29,  21],\n",
       "        [ 46,  40,  32],\n",
       "        ..., \n",
       "        [ 60,  48,  33],\n",
       "        [129, 130, 123],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[ 27,  25,  21],\n",
       "        [ 35,  31,  24],\n",
       "        [ 60,  53,  43],\n",
       "        ..., \n",
       "        [ 72,  60,  48],\n",
       "        [ 29,  30,  25],\n",
       "        [166, 167, 162]],\n",
       "\n",
       "       [[ 62,  60,  56],\n",
       "        [ 27,  23,  15],\n",
       "        [ 81,  72,  59],\n",
       "        ..., \n",
       "        [ 64,  50,  41],\n",
       "        [ 26,  26,  26],\n",
       "        [ 37,  38,  35]]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 32, 32, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray(labels)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Save the image arrays and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wiki.python.org/moin/UsingPickle\n",
    "import pickle\n",
    "pickle.dump( X, open( \"imagearray.pkl\", \"wb\" ) )\n",
    "pickle.dump( Y, open( \"imagearray_labels.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(files, open(\"filenames.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Import pickle files whenever the kernel is restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = pickle.load( open( \"imagearray.pkl\", \"rb\" ) )\n",
    "Y = pickle.load(open(\"imagearray_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Check that image arrays are readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a46a129b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plotData = X[0]\n",
    "plt.imshow(plotData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Deep Learning Model\n",
    "I am creating a convolutional neural network using keras adapted from:\n",
    "* https://github.com/nikbearbrown/NEU_COE/blob/master/CSYE_7245/Week_12/02_Convolutional_Neural_Network.ipynb \n",
    "* https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "batch_size = 32\n",
    "num_classes = 1\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_facedetection.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model=Sequential()\n",
    "\n",
    "# Add convolution layer\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape = X_train.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add second convolution\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add third convolution\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add fourth convolution\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add second pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add dropout layer to regularized network \n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add final dense layer \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add optimizer\n",
    "opt=keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75000 samples, validate on 25000 samples\n",
      "Epoch 1/100\n",
      "75000/75000 [==============================] - 772s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 2/100\n",
      "75000/75000 [==============================] - 815s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 3/100\n",
      "75000/75000 [==============================] - 716s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 4/100\n",
      "75000/75000 [==============================] - 1056s 14ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 5/100\n",
      "75000/75000 [==============================] - 842s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 6/100\n",
      "75000/75000 [==============================] - 998s 13ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 7/100\n",
      "75000/75000 [==============================] - 949s 13ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 8/100\n",
      "75000/75000 [==============================] - 782s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 9/100\n",
      "75000/75000 [==============================] - 798s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 10/100\n",
      "75000/75000 [==============================] - 827s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 11/100\n",
      "75000/75000 [==============================] - 886s 12ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 12/100\n",
      "75000/75000 [==============================] - 764s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 13/100\n",
      "75000/75000 [==============================] - 859s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 14/100\n",
      "75000/75000 [==============================] - 735s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 15/100\n",
      "75000/75000 [==============================] - 820s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 16/100\n",
      "75000/75000 [==============================] - 964s 13ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 17/100\n",
      "75000/75000 [==============================] - 756s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 18/100\n",
      "75000/75000 [==============================] - 852s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 19/100\n",
      "75000/75000 [==============================] - 1387s 18ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 20/100\n",
      "75000/75000 [==============================] - 1331s 18ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 21/100\n",
      "75000/75000 [==============================] - 933s 12ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 22/100\n",
      "75000/75000 [==============================] - 799s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 23/100\n",
      "75000/75000 [==============================] - 827s 11ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 24/100\n",
      "75000/75000 [==============================] - 969s 13ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 25/100\n",
      "75000/75000 [==============================] - 1089s 15ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 26/100\n",
      "75000/75000 [==============================] - 985s 13ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 27/100\n",
      "75000/75000 [==============================] - 876s 12ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 28/100\n",
      "75000/75000 [==============================] - 1333s 18ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 29/100\n",
      "75000/75000 [==============================] - 1640s 22ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 30/100\n",
      "75000/75000 [==============================] - 1387s 18ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 31/100\n",
      "75000/75000 [==============================] - 1528s 20ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 32/100\n",
      "75000/75000 [==============================] - 1474s 20ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 33/100\n",
      "75000/75000 [==============================] - 1352s 18ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 34/100\n",
      "75000/75000 [==============================] - 1099s 15ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 35/100\n",
      "75000/75000 [==============================] - 1012s 13ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 36/100\n",
      "75000/75000 [==============================] - 1060s 14ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 37/100\n",
      "75000/75000 [==============================] - 753s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 38/100\n",
      "75000/75000 [==============================] - 682s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 39/100\n",
      "75000/75000 [==============================] - 653s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 40/100\n",
      "75000/75000 [==============================] - 662s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 41/100\n",
      "75000/75000 [==============================] - 719s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 42/100\n",
      "75000/75000 [==============================] - 715s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 43/100\n",
      "75000/75000 [==============================] - 686s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 44/100\n",
      "75000/75000 [==============================] - 722s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 45/100\n",
      "75000/75000 [==============================] - 676s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 46/100\n",
      "75000/75000 [==============================] - 688s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 47/100\n",
      "75000/75000 [==============================] - 705s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 48/100\n",
      "75000/75000 [==============================] - 722s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 49/100\n",
      "75000/75000 [==============================] - 676s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 50/100\n",
      "75000/75000 [==============================] - 662s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 51/100\n",
      "75000/75000 [==============================] - 712s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 52/100\n",
      "75000/75000 [==============================] - 648s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 53/100\n",
      "75000/75000 [==============================] - 660s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 54/100\n",
      "75000/75000 [==============================] - 683s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 55/100\n",
      "75000/75000 [==============================] - 668s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 56/100\n",
      "75000/75000 [==============================] - 654s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 57/100\n",
      "75000/75000 [==============================] - 665s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 58/100\n",
      "75000/75000 [==============================] - 641s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "75000/75000 [==============================] - 628s 8ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 60/100\n",
      "75000/75000 [==============================] - 634s 8ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 61/100\n",
      "75000/75000 [==============================] - 709s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 62/100\n",
      "75000/75000 [==============================] - 713s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 63/100\n",
      "75000/75000 [==============================] - 694s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 64/100\n",
      "75000/75000 [==============================] - 626s 8ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 65/100\n",
      "75000/75000 [==============================] - 630s 8ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 66/100\n",
      "75000/75000 [==============================] - 692s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 67/100\n",
      "75000/75000 [==============================] - 690s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 68/100\n",
      "75000/75000 [==============================] - 681s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 69/100\n",
      "75000/75000 [==============================] - 640s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 70/100\n",
      "75000/75000 [==============================] - 652s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 71/100\n",
      "75000/75000 [==============================] - 640s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 72/100\n",
      "75000/75000 [==============================] - 697s 9ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 73/100\n",
      "75000/75000 [==============================] - 725s 10ms/step - loss: 7.9693 - acc: 0.5001 - val_loss: 7.9769 - val_acc: 0.4996\n",
      "Epoch 74/100\n",
      "13120/75000 [====>.........................] - ETA: 8:26 - loss: 7.8983 - acc: 0.5046"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = batch_size, epochs=epochs, validation_data=(X_test, Y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
